{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3e4239",
   "metadata": {},
   "source": [
    "# 인공 작사가 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a8d780",
   "metadata": {},
   "source": [
    "### 라이브러리 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f0e277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import glob # glob 함수 : 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환\n",
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026262fc",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0400c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/aiffel/aiffel/lyricist/data/data': Read-only file system\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/aiffel/lyricist/models\n",
    "!ln -s ~/data ~/aiffel/lyricist/data\n",
    "# 이미 이전에 불러와서 failed가 떴다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0203c90c",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f20a8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Busted flat in Baton Rouge, waitin' for a train\", \"And I's feelin' near as faded as my jeans\", 'Bobby thumbed a diesel down, just before it rained']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os, re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path) # txt_file_path 경로에 있는 모든 파일명을 리스트 형식으로 txt_list에 할당\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines() # splitlines()  : 여러라인으로 구분되어 있는 문자열을 한라인씩 분리하여 리스트로 반환\n",
    "        raw_corpus.extend(raw) \n",
    "        \n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a52790",
   "metadata": {},
   "source": [
    "## Step 3. 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0611f16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busted flat in Baton Rouge, waitin' for a train\n",
      "And I's feelin' near as faded as my jeans\n",
      "Bobby thumbed a diesel down, just before it rained\n",
      "It rode us all the way to New Orleans I pulled my harpoon out of my dirty red bandanna\n",
      "I was playin' soft while Bobby sang the blues, yeah\n",
      "Windshield wipers slappin' time, I was holdin' Bobby's hand in mine\n",
      "We sang every song that driver knew Freedom's just another word for nothin' left to lose\n",
      "Nothin', don't mean nothin' hon' if it ain't free, no no\n",
      "And, feelin' good was easy, Lord, when he sang the blues\n",
      "You know, feelin' good was good enough for me\n"
     ]
    }
   ],
   "source": [
    "# 필요없는 문장 지우기\n",
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue # 길이가 0인 문장 건너뛰기\n",
    "        \n",
    "    if idx > 9 : break # 문장 10개만 확인\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3237b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 전처리\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 소문자로 바꾸고, 양쪽 공백 지우기\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 특수문자 양쪽에 공백 넣기\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개의 공백은 하나의 공백으로 바꾸기\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꾸기\n",
    "    sentence = sentence.strip() # 다시 양쪽 공백 지우기\n",
    "    sentence = '< start > ' + sentence + ' < end >' # 문장 시작에는 < start > , 끝에는 < end >추가\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c4d1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_split = preprocess_sentence(sentence).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fdfeba",
   "metadata": {},
   "source": [
    "- 공백 기준으로 분할하여 각 문장을 토큰화했을 때처럼 만들어주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce559b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> busted flat in baton rouge , waitin for a train <end>', '<start> and i s feelin near as faded as my jeans <end>', '<start> bobby thumbed a diesel down , just before it rained <end>', '<start> it rode us all the way to new orleans i pulled my harpoon out of my dirty red bandanna <end>', '<start> i was playin soft while bobby sang the blues , yeah <end>', '<start> windshield wipers slappin time , i was holdin bobby s hand in mine <end>', '<start> we sang every song that driver knew freedom s just another word for nothin left to lose <end>', '<start> nothin , don t mean nothin hon if it ain t free , no no <end>', '<start> and , feelin good was easy , lord , when he sang the blues <end>', '<start> you know , feelin good was good enough for me <end>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "175986"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정제 데이터 구축하기\n",
    "corpus = []\n",
    "\n",
    "# raw_corpus list에 저장된 문장들을 순서대로 반환하여 sentence에 저장\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue # 길이가 0인 문장 제외\n",
    "    if len(sentence_split) >= 17: continue # <start>, <end> 제외하고 토큰이 15개를 넘어가는 문장 제외\n",
    "    \n",
    "    # 앞서 구현한 preprocess_sentence() 함수를 이용하여 문장을 정제를 하고 담아주기\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "\n",
    "# 정제된 결과를 10개만 확인\n",
    "print(corpus[:10])\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5237a2d1",
   "metadata": {},
   "source": [
    "## Step 4. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5fea447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2 3609 1692 ...    0    0    0]\n",
      " [   2    8    5 ...    0    0    0]\n",
      " [   2  804 7664 ...    0    0    0]\n",
      " ...\n",
      " [   2    5   22 ...    0    0    0]\n",
      " [   2    5   22 ...    0    0    0]\n",
      " [   2    5   22 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f43920cbd60>\n"
     ]
    }
   ],
   "source": [
    "# 15,000단어를 기억할 수 있는 tokenizer 만들기\n",
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=15000,\n",
    "        filters=' ', # 이미 문장을 정제했기 떄문에 filters는 필요없음\n",
    "        oov_token=\"<unk>\" # 15000단어에 포함되지 못한 단어는 \"\"로 바꾸기\n",
    "    )\n",
    "    \n",
    "    # corpus를 이용해 tokenizer 내부의 단어장 완성\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰주기\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    \n",
    "    print(tensor, tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce63b2",
   "metadata": {},
   "source": [
    "- 텐서플로우의 Tokenizer와 pad_sequences를 사용해서 토큰화할 수 있다.\n",
    "- tf.keras.preprocessing.text.Tokenizer 패키지 : 정제된 데이터를 토큰화하고, 단어 사전을 만들어주며, 데이터를 숫자로 변환(벡터화 vectorize)  \n",
    "- tokenizer.fit_on_texts(texts): 문자 데이터를 입력받아 리스트의 형태로 변환하는 메서드  \n",
    "- tokenizer.texts_to_sequences(texts): 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환하는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d4402d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2 3609 1692   14 7058 3995    4 1100   28    9  681    3    0    0]\n",
      " [   2    8    5   16  513  848   81 2589   81   13  948    3    0    0]\n",
      " [   2  804 7664    9 6048   60    4   36  185   11 4575    3    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 3번째 행, 14번째 열까지만 출력\n",
    "print(tensor[:3, :14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec82a3",
   "metadata": {},
   "source": [
    "- 텐서 데이터는 모두 정수로 이루어져 있으며, 이 숫자는 tokenizer에 구축된 단어 사전의 인덱스이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b0673fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.index_word: 현재 계산된 단어의 인덱스와 인덱스에 해당하는 단어를 dictionary 형태로 반환\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8daf59a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2 3609 1692   14 7058 3995    4 1100   28    9  681    3    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "[3609 1692   14 7058 3995    4 1100   28    9  681    3    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성하기\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높다.\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성하기\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83e114ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140788, 346) (140788, 346)\n",
      "(35198, 346) (35198, 346)\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터와 평가데이터 분리하기(총 데이터의 20%를 평가 데이터셋으로 사용)\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=20)\n",
    "\n",
    "print(enc_train.shape, dec_train.shape)\n",
    "print(enc_val.shape, dec_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee766fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 346), (256, 346)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 객체를 생성\n",
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "# tokenizer가 구축한 단어사전 내 15000개와, 여기 포함되지 않은 0:를 포함하여 15001개\n",
    "# tokenizer.num_words: 주어진 데이터의 문장들에서 빈도수가 높은 n개의 단어만 선택\n",
    "# tokenize() 함수에서 num_words를 15000개로 선언했기 때문에, tokenizer.num_words의 값은 15000   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋 만들기\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c48da",
   "metadata": {},
   "source": [
    "## Step 5. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50f27b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        # 1개의 Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성\n",
    "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
    "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다. \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "# embedding size 값이 커질수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만 그만큼 충분한 데이터가 없으면 안좋은 결과 값을 가져온다.  \n",
    "embedding_size = 128 # 워드 벡터의 차원수, 단어가 추상적으로 표현되는 크기\n",
    "hidden_size = 128 # 모델에 얼마나 많은 일꾼을 둘 것인가? 정도\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size) # tokenizer.num_words에 +1인 이유는 문장에 없는 pad가 사용되었기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c2ae5",
   "metadata": {},
   "source": [
    "- 입력 텐서에 들어 있는 단어 사전의 인덱스 -> Embedding 레이어 : 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔주기 -> 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현(representation)으로 사용  \n",
    "- embedding_size = 2048, hidden_size = 2048로 설정했을 때, 한 배치만 불러온 데이터를 모델에 넣어봤을 때, 크기가 너무 큰 나머지 resource exhausted error가 발생했다.  \n",
    "- embedding_size = 1024, hidden_size = 1024로 설정했을 때, 한 배치만 불러온 데이터를 모델에 넣어봤을 때, 다시 resourceexhaustederror가 발생했다. 여전히 크기가 너무 컸던 거 같다.  \n",
    "- embedding_size = 256, hidden_size = 1024로 설정했을 때와 embedding_size = 128, hidden_size = 128으로 설정했을 때에도 계속해서 같은 에러가 발생했고, 처음부터 다시 셀을 돌려보기로 했다. 그러면서 embedding_size = 128, hidden_size = 128으로 설정했는데, 더이상 resource exhausted error가 발생하지 않았다. 반복해서 셀을 돌려서 그런지 같은 숫자로 해도 더이상 에러가 발생하지 않았다. 그리고 너무 큰 숫자로 embedding_size와 hidden_size를 결정하는 것이 좋은 것만은 아니라고 느꼈다. 알맞는 size를 찾는 것이 더 중요하다는 것을 다시 한 번 알 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31c1d36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 346, 15001), dtype=float32, numpy=\n",
       "array([[[ 1.27412946e-04,  1.30685003e-04, -1.84746314e-04, ...,\n",
       "         -4.13522102e-05, -7.86557357e-05,  3.36227022e-05],\n",
       "        [ 2.35789528e-04,  2.56934029e-04, -2.12266808e-04, ...,\n",
       "         -1.04038663e-04, -1.84200209e-04, -1.68555256e-04],\n",
       "        [ 2.95492937e-04,  4.61630290e-04, -9.11760580e-05, ...,\n",
       "         -1.77651586e-04, -3.13620432e-04, -4.15153976e-04],\n",
       "        ...,\n",
       "        [ 6.65247906e-04,  1.81481242e-03,  1.51780387e-03, ...,\n",
       "         -1.44216130e-04, -2.51107704e-04, -2.47210683e-03],\n",
       "        [ 6.65247906e-04,  1.81481254e-03,  1.51780387e-03, ...,\n",
       "         -1.44216130e-04, -2.51107733e-04, -2.47210683e-03],\n",
       "        [ 6.65247906e-04,  1.81481242e-03,  1.51780387e-03, ...,\n",
       "         -1.44216130e-04, -2.51107704e-04, -2.47210683e-03]],\n",
       "\n",
       "       [[ 1.27412946e-04,  1.30685003e-04, -1.84746314e-04, ...,\n",
       "         -4.13522102e-05, -7.86557357e-05,  3.36227022e-05],\n",
       "        [ 1.04817140e-04,  1.54884547e-04, -3.50023503e-04, ...,\n",
       "         -6.77767966e-05, -2.00766110e-04, -1.97235295e-05],\n",
       "        [ 1.21593475e-04,  4.90341481e-05, -2.04624157e-04, ...,\n",
       "         -8.47376286e-05, -1.25600869e-04, -5.88254006e-05],\n",
       "        ...,\n",
       "        [ 6.65247964e-04,  1.81481254e-03,  1.51780411e-03, ...,\n",
       "         -1.44216319e-04, -2.51108082e-04, -2.47210637e-03],\n",
       "        [ 6.65247964e-04,  1.81481254e-03,  1.51780411e-03, ...,\n",
       "         -1.44216319e-04, -2.51108082e-04, -2.47210637e-03],\n",
       "        [ 6.65247964e-04,  1.81481254e-03,  1.51780411e-03, ...,\n",
       "         -1.44216319e-04, -2.51108082e-04, -2.47210637e-03]],\n",
       "\n",
       "       [[ 1.27412946e-04,  1.30685003e-04, -1.84746314e-04, ...,\n",
       "         -4.13522102e-05, -7.86557357e-05,  3.36227022e-05],\n",
       "        [ 2.37688597e-04,  2.81091838e-04, -1.97234345e-04, ...,\n",
       "          6.39651626e-05, -1.83094817e-04,  2.80614368e-05],\n",
       "        [ 3.83251463e-04,  2.86269700e-04, -9.11684110e-05, ...,\n",
       "          1.08256572e-04, -1.69618565e-04,  4.33840723e-05],\n",
       "        ...,\n",
       "        [ 6.65247615e-04,  1.81481207e-03,  1.51780364e-03, ...,\n",
       "         -1.44216043e-04, -2.51108024e-04, -2.47210613e-03],\n",
       "        [ 6.65247731e-04,  1.81481196e-03,  1.51780352e-03, ...,\n",
       "         -1.44216159e-04, -2.51107966e-04, -2.47210613e-03],\n",
       "        [ 6.65247615e-04,  1.81481207e-03,  1.51780364e-03, ...,\n",
       "         -1.44216043e-04, -2.51108024e-04, -2.47210613e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.27412946e-04,  1.30685003e-04, -1.84746314e-04, ...,\n",
       "         -4.13522102e-05, -7.86557357e-05,  3.36227022e-05],\n",
       "        [ 3.04995308e-04,  1.77890091e-04, -2.93592107e-04, ...,\n",
       "          5.62631249e-05, -4.03395643e-05,  1.56880138e-04],\n",
       "        [ 2.99975713e-04,  1.72774890e-04, -4.20217955e-04, ...,\n",
       "          1.69855339e-04,  4.07456137e-05,  2.99199019e-04],\n",
       "        ...,\n",
       "        [ 6.65247848e-04,  1.81481207e-03,  1.51780376e-03, ...,\n",
       "         -1.44216217e-04, -2.51108198e-04, -2.47210660e-03],\n",
       "        [ 6.65247848e-04,  1.81481207e-03,  1.51780376e-03, ...,\n",
       "         -1.44216217e-04, -2.51108198e-04, -2.47210660e-03],\n",
       "        [ 6.65247848e-04,  1.81481207e-03,  1.51780376e-03, ...,\n",
       "         -1.44216217e-04, -2.51108198e-04, -2.47210660e-03]],\n",
       "\n",
       "       [[ 1.27412946e-04,  1.30685003e-04, -1.84746314e-04, ...,\n",
       "         -4.13522102e-05, -7.86557357e-05,  3.36227022e-05],\n",
       "        [ 3.04631860e-04,  1.56372233e-04, -3.52807489e-04, ...,\n",
       "         -9.85567822e-05, -7.58349925e-05,  2.11239676e-04],\n",
       "        [ 5.20282250e-04,  2.60422763e-04, -4.51558211e-04, ...,\n",
       "         -1.55230926e-04, -1.64787038e-04,  2.35567917e-04],\n",
       "        ...,\n",
       "        [ 6.65247615e-04,  1.81481289e-03,  1.51780376e-03, ...,\n",
       "         -1.44216494e-04, -2.51108548e-04, -2.47210660e-03],\n",
       "        [ 6.65247615e-04,  1.81481289e-03,  1.51780376e-03, ...,\n",
       "         -1.44216494e-04, -2.51108548e-04, -2.47210660e-03],\n",
       "        [ 6.65247615e-04,  1.81481289e-03,  1.51780376e-03, ...,\n",
       "         -1.44216494e-04, -2.51108548e-04, -2.47210660e-03]],\n",
       "\n",
       "       [[ 1.27412946e-04,  1.30685003e-04, -1.84746314e-04, ...,\n",
       "         -4.13522102e-05, -7.86557357e-05,  3.36227022e-05],\n",
       "        [ 1.46908525e-04,  2.15909924e-04, -2.61833862e-04, ...,\n",
       "         -7.48307939e-05, -1.35173468e-04,  1.37455854e-05],\n",
       "        [ 1.93168395e-04,  2.95174366e-04, -1.99467540e-04, ...,\n",
       "         -6.63027386e-05, -3.80439975e-04, -7.26069120e-05],\n",
       "        ...,\n",
       "        [ 6.65247964e-04,  1.81481231e-03,  1.51780422e-03, ...,\n",
       "         -1.44216086e-04, -2.51108519e-04, -2.47210613e-03],\n",
       "        [ 6.65247964e-04,  1.81481231e-03,  1.51780422e-03, ...,\n",
       "         -1.44216086e-04, -2.51108519e-04, -2.47210613e-03],\n",
       "        [ 6.65247964e-04,  1.81481231e-03,  1.51780422e-03, ...,\n",
       "         -1.44216086e-04, -2.51108519e-04, -2.47210613e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법(model에 데이터를 아주 조금 넣어보는 것)\n",
    "# model의 input shape이 결정되면서 model.build()가 자동으로 호출됨.\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어보기\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2104bb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  1920128   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  131584    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1935129   \n",
      "=================================================================\n",
      "Total params: 4,118,425\n",
      "Trainable params: 4,118,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델의 구조를 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfe37537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "687/687 [==============================] - 553s 801ms/step - loss: 0.4794 - val_loss: 0.1593\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 554s 806ms/step - loss: 0.1602 - val_loss: 0.1520\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 554s 806ms/step - loss: 0.1497 - val_loss: 0.1471\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 554s 806ms/step - loss: 0.1454 - val_loss: 0.1427\n",
      "Epoch 5/10\n",
      "687/687 [==============================] - 555s 808ms/step - loss: 0.1416 - val_loss: 0.1395\n",
      "Epoch 6/10\n",
      "687/687 [==============================] - 558s 812ms/step - loss: 0.1387 - val_loss: 0.1366\n",
      "Epoch 7/10\n",
      "687/687 [==============================] - 559s 813ms/step - loss: 0.1357 - val_loss: 0.1333\n",
      "Epoch 8/10\n",
      "687/687 [==============================] - 560s 815ms/step - loss: 0.1327 - val_loss: 0.1303\n",
      "Epoch 9/10\n",
      "687/687 [==============================] - 560s 815ms/step - loss: 0.1298 - val_loss: 0.1275\n",
      "Epoch 10/10\n",
      "687/687 [==============================] - 560s 815ms/step - loss: 0.1271 - val_loss: 0.1247\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam() \n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수\n",
    "    from_logits=True, # 기본값은 False. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다.(softmax함수가 적용되지 않았다는걸 의미) \n",
    "    reduction='none'  # 기본값은 SUM. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
    ")\n",
    "# 모델을 학습시키키 위한 학습과정을 설정하는 단계\n",
    "model.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정\n",
    "hist = model.fit(dataset, epochs=10, validation_data=(enc_val, dec_val)) # 만들어둔 데이터셋으로 모델을 학습.(10번 학습을 반복)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "299c2518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAApbUlEQVR4nO3de3Sc9X3n8fd37jOSRja2wZZtsEkMscTFJIal6wXSTUogNEAOTYCGhqQ95OQcaJKlzcZpWtrQkxMSsmlK6xRoS07SXCiFZOssTt2mBZzshgQDTsHmZpuLJdtYsmzdpdHMfPePeSSPlJEs2Ro9unxe58yZ5z5fDVgf/Z7f73kec3dERERGi4RdgIiIzEwKCBERqUgBISIiFSkgRESkIgWEiIhUFAu7gKmyePFiX7VqVdhliIjMKk8//XSbuy+ptG7OBMSqVavYvn172GWIiMwqZvb6WOt0iklERCpSQIiISEUKCBERqWjO9EFUMjg4SHNzM/39/WGXMmulUilWrFhBPB4PuxQRmWZzOiCam5upq6tj1apVmFnY5cw67s7hw4dpbm5m9erVYZcjItNsTp9i6u/vZ9GiRQqHE2RmLFq0SC0wkXlqTgcEoHA4Sfr+ROavOR8Qx5MvFHmzs5/eXD7sUkREZpR5HxBm8GZnP939Ux8QR48e5etf//oJ7fve976Xo0ePTnj7P/uzP+MrX/nKCX2WiEgl8z4gopEIiViEvsHClB97vIDI58cPpC1btrBgwYIpr0lEZKLmfUAApOPRqgTExo0b2bNnD+vWrePTn/40jz/+OJdccglXX301jY2NAFx77bW84x3voKmpifvvv39431WrVtHW1sZrr73G2rVrueWWW2hqauLyyy+nr69v3M/dsWMHF198Meeddx7vf//7OXLkCAD33HMPjY2NnHfeedxwww0APPHEE6xbt45169ZxwQUX0NXVNeXfg4jMTnN6mGu5z/9wJ7v2d1ZcN1gokssXqUlO7utobMjyp+9rGnP9XXfdxfPPP8+OHTsAePzxx3nmmWd4/vnnh4eNPvDAA5xyyin09fVx4YUXct1117Fo0aIRx3nllVf43ve+x9/+7d/ywQ9+kEceeYSbbrppzM/98Ic/zF/91V9x2WWXcccdd/D5z3+er33ta9x11128+uqrJJPJ4dNXX/nKV9i0aRMbNmygu7ubVCo1qe9AROYutSCASDBSpzANz+e+6KKLRlxTcM8993D++edz8cUXs2/fPl555ZVf2Wf16tWsW7cOgHe84x289tprYx6/o6ODo0ePctlllwFw8803s23bNgDOO+88PvShD/Htb3+bWKwUhhs2bOD222/nnnvu4ejRo8PLRUTmzW+D8f7SHywUeeFAJw0L0iyuTVa1jpqamuHpxx9/nB//+Mf87Gc/I5PJ8M53vrPiNQfJ5LGaotHocU8xjeXRRx9l27Zt/PCHP+QLX/gCzz33HBs3buSqq65iy5YtbNiwga1bt/K2t73thI4vInOLWhBAPBohFonQl5vafoi6urpxz+l3dHSwcOFCMpkML774Ik8++eRJf2Z9fT0LFy7kJz/5CQD/8A//wGWXXUaxWGTfvn38+q//Ol/60pfo6Oigu7ubPXv2cO655/KZz3yGCy+8kBdffPGkaxCRuWHetCCOJ52Y+o7qRYsWsWHDBs455xyuvPJKrrrqqhHrr7jiCu69917Wrl3L2WefzcUXXzwln/vNb36Tj3/84/T29nLmmWfyjW98g0KhwE033URHRwfuzic+8QkWLFjAn/zJn/DYY48RiURoamriyiuvnJIaRGT2M5+G8+7TYf369T76gUEvvPACa9eundD+Bzr6aOvO0dSQHe6TkJLJfI8iMruY2dPuvr7SOp1iCqTjUdydgSoMdxURmY0UEIF0PApA32Ax5EpERGYGBUQgEYsQMaNfLQgREUABMczMSldUT/FIJhGR2aqqAWFmV5jZS2a228w2jrPddWbmZrY+mF9lZn1mtiN43VvNOoekgpFMc6XjXkTkZFRtmKuZRYFNwG8AzcBTZrbZ3XeN2q4O+CTw81GH2OPu66pVXyXpeITD7uTyRZJBn4SIyHxVzRbERcBud9/r7jngQeCaCtv9OfAlIPTHlh3rqA7vNFNtbe2klouIVEs1A2I5sK9svjlYNszM3g6sdPdHK+y/2syeNbMnzOySKtY5LBmPYqijWkQEQuykNrMI8FXgDyqsPgCc7u4XALcD3zWzbIVjfMzMtpvZ9tbW1pOuKWJGMh6ZsqGuGzduZNOmTcPzQw/16e7u5l3vehdvf/vbOffcc/nnf/7nCR/T3fn0pz/NOeecw7nnnss//uM/AnDgwAEuvfRS1q1bxznnnMNPfvITCoUCH/nIR4a3/Yu/+Isp+blEZH6o5q02WoCVZfMrgmVD6oBzgMeD5x4vBTab2dXuvh0YAHD3p81sD3AWMOJSaXe/H7gfSldSj1vNjzbCweeOW/Tp+QKFokNiAl/N0nPhyrvGXH399dfzqU99iltvvRWAhx56iK1bt5JKpfjBD35ANpulra2Niy++mKuvvnpCz3/+/ve/z44dO/jlL39JW1sbF154IZdeeinf/e53ec973sPnPvc5CoUCvb297Nixg5aWFp5//nmAST2hTkSkmgHxFLDGzFZTCoYbgN8eWunuHcDioXkzexz4Q3ffbmZLgHZ3L5jZmcAaYG8Vax0WMSPvThEnwsndcuOCCy7g0KFD7N+/n9bWVhYuXMjKlSsZHBzkj/7oj9i2bRuRSISWlhbefPNNli5detxj/vSnP+XGG28kGo1y2mmncdlll/HUU09x4YUX8ru/+7sMDg5y7bXXsm7dOs4880z27t3L7//+73PVVVdx+eWXn9TPIyLzS9UCwt3zZnYbsBWIAg+4+04zuxPY7u6bx9n9UuBOMxsEisDH3b39pAoa5y/9crmBPHtbu1m9uIa6VPykPhLgAx/4AA8//DAHDx7k+uuvB+A73/kOra2tPP3008TjcVatWlXxNt+Tcemll7Jt2zYeffRRPvKRj3D77bfz4Q9/mF/+8pds3bqVe++9l4ceeogHHnjgpH8mEZkfqno3V3ffAmwZteyOMbZ9Z9n0I8Aj1axtLOl4qVumL1eYkoC4/vrrueWWW2hra+OJJ54ASrf5PvXUU4nH4zz22GO8/vrrEz7eJZdcwn333cfNN99Me3s727Zt4+677+b1119nxYoV3HLLLQwMDPDMM8/w3ve+l0QiwXXXXcfZZ5897lPoRERG0+2+R4lGIiRikSkb6trU1ERXVxfLly9n2bJlAHzoQx/ife97H+eeey7r16+f1AN63v/+9/Ozn/2M888/HzPjy1/+MkuXLuWb3/wmd999N/F4nNraWr71rW/R0tLCRz/6UYrFUqf7F7/4xSn5mURkftDtvit4/XAP/YNFzl5aN1XlzWq63bfI3KXbfU9SKh5lYGg0k4jIPKWAqGDoimpdMCci89mcD4gTOYU2E265MVPMlVOQIjJ5czogUqkUhw8fnvQvuVjUiEUi9M/zW3+7O4cPHyaVSoVdioiEYE6PYlqxYgXNzc2cyG04DncP0Fp0urLz+5djKpVixYoVYZchIiGY0wERj8dZvXr1Ce37xR+9wDd++hrPf/49JGJzuqElIlKRfvONoamhnlyhyO5D3WGXIiISCgXEGBqXlW4eu+tAZ8iViIiEQwExhtWLa0jHo+zc3xF2KSIioVBAjCEaMdYuq2PnfrUgRGR+UkCMo7Ehywv7O3UtgIjMSwqIcTQ11NM1kGdfe1/YpYiITDsFxDiaGkod1eqHEJH5SAExjrNOqyMaMY1kEpF5SQExjlQ8yluX1KqjWkTmJQXEcTQ1ZHWKSUTmJQXEcTQ2ZHmzc4C27oGwSxERmVZVDQgzu8LMXjKz3Wa2cZztrjMzN7P1Zcs+G+z3kpm9p5p1jqcx6KjepdNMIjLPVC0gzCwKbAKuBBqBG82sscJ2dcAngZ+XLWsEbgCagCuArwfHm3ZDt9xQP4SIzDfVbEFcBOx2973ungMeBK6psN2fA18C+suWXQM86O4D7v4qsDs43rRbkEmwfEFaI5lEZN6pZkAsB/aVzTcHy4aZ2duBle7+6GT3Dfb/mJltN7PtJ/LMh4lSR7WIzEehdVKbWQT4KvAHJ3oMd7/f3de7+/olS5ZMXXGjNDZkebWth56BfNU+Q0RkpqlmQLQAK8vmVwTLhtQB5wCPm9lrwMXA5qCj+nj7Tqumhnrc4cWDXWGVICIy7aoZEE8Ba8xstZklKHU6bx5a6e4d7r7Y3Ve5+yrgSeBqd98ebHeDmSXNbDWwBvhFFWsdV9PwSCadZhKR+aNqjxx197yZ3QZsBaLAA+6+08zuBLa7++Zx9t1pZg8Bu4A8cKu7F6pV6/Esq0+xIBPXSCYRmVeq+kxqd98CbBm17I4xtn3nqPkvAF+oWnGTYGY0NWQ1kklE5hVdST1BTQ31vHiwi8FCMexSRESmhQJighqXZcnli+xp7Q67FBGRaaGAmKAm3XJDROYZBcQEnbmkllQ8oo5qEZk3FBATFI0YZy/VFdUiMn8oICahqSHLrv2duHvYpYiIVJ0CYhKaGrJ09udpPtIXdikiIlWngJgE3fpbROYTBcQkvG1ploihC+ZEZF5QQExCOhHlLUtqdU8mEZkXFBCT1NiQ1SkmEZkXFBCT1NSQ5UBHP+09ubBLERGpKgXEJDU11AO6olpE5j4FxCQdG8mkfggRmdsUEJO0sCZBQ31KI5lEZM5TQJyAxoZ6dVSLyJyngDgBjQ1Z9rZ205cL7SF3IiJVp4A4AU0NWYoOLx5UK0JE5i4FxAkYejaETjOJyFxW1YAwsyvM7CUz221mGyus/7iZPWdmO8zsp2bWGCxfZWZ9wfIdZnZvNeucrOUL0tSn4woIEZnTYtU6sJlFgU3AbwDNwFNmttndd5Vt9l13vzfY/mrgq8AVwbo97r6uWvWdDDOjcVlWI5lEZE6rZgviImC3u+919xzwIHBN+QbuXv4btgaYNQ9aaGrI8uKBTvKFYtiliIhURTUDYjmwr2y+OVg2gpndamZ7gC8DnyhbtdrMnjWzJ8zskkofYGYfM7PtZra9tbV1Kms/rsaGLAP5Invbeqb1c0VEpkvondTuvsnd3wJ8BvjjYPEB4HR3vwC4HfiumWUr7Hu/u6939/VLliyZvqLRLTdEZO6rZkC0ACvL5lcEy8byIHAtgLsPuPvhYPppYA9wVnXKPDFvWVJDIhbRLTdEZM6qZkA8Bawxs9VmlgBuADaXb2Bma8pmrwJeCZYvCTq5MbMzgTXA3irWOmmxaIS3La3TSCYRmbOqNorJ3fNmdhuwFYgCD7j7TjO7E9ju7puB28zs3cAgcAS4Odj9UuBOMxsEisDH3b29WrWeqKaGLD96/iDujpmFXY6IyJSqWkAAuPsWYMuoZXeUTX9yjP0eAR6pZm1TobGhnu/9Yh/7O/pZviAddjkiIlMq9E7q2Wz41t8t6ocQkblHAXES1i6rwwxdMCcic5IC4iRkEjHOXFyjjmoRmZMUECepsaFe10KIyJykgDhJTQ1ZWo72cbQ3F3YpIiJTSgFxkoZu/a1WhIjMNQqIkzQ8kkkBISJzjALiJC2qTbI0m9JIJhGZcxQQU6CpIat7MonInKOAmAKNDVn2tPbQP1gIuxQRkSmjgJgCTQ1ZCkXnpYNdYZciIjJlFBBTYOjZEOqoFpG5RAExBVYsTFOXiqkfQkTmFAXEFDAzGpdlNZJJROYUBcQUaWqo58UDXRSKHnYpIiJTYkIBYWafNLOslfy9mT1jZpdXu7jZpLEhS99ggVfbusMuRURkSky0BfG77t4JXA4sBH4HuKtqVc1CQ7fcUEe1iMwVEw2Ioedpvhf4B3ffWbZMgLeeWksiGtE9mURkzphoQDxtZv9KKSC2mlkdpWdFSyAejXDW0lq1IERkzphoQPwesBG40N17gTjw0ePtZGZXmNlLZrbbzDZWWP9xM3vOzHaY2U/NrLFs3WeD/V4ys/dMsM5QNS2rZ9eBTtzVUS0is99EA+LXgJfc/aiZ3QT8MTDuoH8ziwKbgCuBRuDG8gAIfNfdz3X3dcCXga8G+zYCNwBNwBXA14PjzWhNy7O09+Q42NkfdikiIidtogHxN0CvmZ0P/AGwB/jWcfa5CNjt7nvdPQc8CFxTvkHQ8T2kBhj60/sa4EF3H3D3V4HdwfFmtOFbf7foNJOIzH4TDYi8l86bXAP8tbtvAuqOs89yYF/ZfHOwbAQzu9XM9lBqQXxikvt+zMy2m9n21tbWCf4o1bN2WRYzdMGciMwJEw2ILjP7LKXhrY+aWYRSP8RJc/dN7v4W4DOUTl1NZt/73X29u69fsmTJVJRzUmqSMVYvqtEtN0RkTphoQFwPDFC6HuIgsAK4+zj7tAAry+ZXBMvG8iBw7QnuO2OsbchqJJOIzAkTCoggFL4D1JvZbwL97n68PoingDVmttrMEpQ6nTeXb2Bma8pmrwJeCaY3AzeYWdLMVgNrgF9MpNawNTVkaT7SR0ffYNiliIiclIneauODlH5BfwD4IPBzM/ut8fZx9zxwG7AVeAF4yN13mtmdZnZ1sNltZrbTzHYAtwM3B/vuBB4CdgH/Atzq7rPiaTxDt/7WBXMiMtvFJrjd5yhdA3EIwMyWAD8GHh5vJ3ffAmwZteyOsulPjrPvF4AvTLC+GWN4JNP+Dn7tLYtCrkZE5MRNtA8iMhQOgcOT2HdeWVKX5NS6pEYyicisN9EWxL+Y2Vbge8H89YxqGcgxTQ1ZnWISkVlvQgHh7p82s+uADcGi+939B9Ura3ZrbMiy7ZU2+gcLpOIz/gJwEZGKJtqCwN0fAR6pYi1zRlNDPYWi88qb3Zy7oj7sckRETsi4AWFmXRy7/cWIVYC7e7YqVc1yx54N0aGAEJFZa9yAcPfj3U5DKli5MENtMqaOahGZ1TQSqQoiEaNxma6oFpHZTQFRJY0NWV440EmhqGdDiMjspICoksaGLL25Aq8f7gm7FBGRE6KAqJJjHdU6zSQis5MCokrWnFpHPGoKCBGZtRQQVZKIRVhzap1GMonIrKWAqKLSLTc6KD2MT0RkdlFAVFFTQ5a27hyHugbCLkVEZNIUEFXUqGdDiMgspoCoorXLShei6xnVIjIbKSCqqC4VZ9WijEYyicispICossaGrEYyicispICosqaGel4/3Etn/2DYpYiITEpVA8LMrjCzl8xst5ltrLD+djPbZWb/aWb/bmZnlK0rmNmO4LW5mnVWU2NwRfULOs0kIrNM1QLCzKLAJuBKoBG40cwaR232LLDe3c8DHga+XLauz93XBa+rq1VntTUtKwWETjOJyGxTzRbERcBud9/r7jngQeCa8g3c/TF37w1mnwRWVLGeUJyaTbG4NqmOahGZdaoZEMuBfWXzzcGysfwe8KOy+ZSZbTezJ83s2ko7mNnHgm22t7a2nnTB1dLUoGdDiMjsMyM6qc3sJmA9cHfZ4jPcfT3w28DXzOwto/dz9/vdfb27r1+yZMk0VTt5jQ1Zdh/qIpcvhl2KiMiEVTMgWoCVZfMrgmUjmNm7gc8BV7v78D0p3L0leN8LPA5cUMVaq6qpIctgwXn5za6wSxERmbBqBsRTwBozW21mCeAGYMRoJDO7ALiPUjgcKlu+0MySwfRiYAOwq4q1VlWTbrkhIrNQrFoHdve8md0GbAWiwAPuvtPM7gS2u/tmSqeUaoF/MjOAN4IRS2uB+8ysSCnE7nL3WRsQZ5ySoSYR1UgmEZlVqhYQAO6+BdgyatkdZdPvHmO//wecW83aplMkYqxdltU9mURkVpkRndTzQenZEJ0Ui3o2hIjMDgqIadLYkKUnV+CN9t7jbywiMgMoIKbJUEe1rocQkdlCATFN1pxWSyxi6ocQkVlDATFNkrEobz21ViOZRGTWUEBMo6aGep1iEpFZQwExjZoasrR2DXCoqz/sUkREjksBMY2Gng2hK6pFZDZQQEyjoYDQaSYRmQ0UENMom4pz+ikZtSBEZFZQQEyzxmVZjWQSkVlBATHNmhqyvNrWQ/dAPuxSRETGpYCYZk3LS/0QL6gVISIznAJimjUu07MhRGR2UEBMs9OySRbVJHTLDRGZ8RQQ08zMaGzIaqiriMx4CogQNDZkeeXNbnL5YtiliIiMSQERgqaGenKFIrsPdYddiojImBQQIWgavqJa/RAiMnNVNSDM7Aoze8nMdpvZxgrrbzezXWb2n2b272Z2Rtm6m83sleB1czXrnG6rFtWQjkd1wZyIzGhVCwgziwKbgCuBRuBGM2sctdmzwHp3Pw94GPhysO8pwJ8C/wW4CPhTM1tYrVqnWzRirF1Wp45qEZnRqtmCuAjY7e573T0HPAhcU76Buz/m7kMPaX4SWBFMvwf4N3dvd/cjwL8BV1Sx1mnX1FDPC/s7KRY97FJERCqqZkAsB/aVzTcHy8bye8CPJrOvmX3MzLab2fbW1taTLHd6NTZk6RrI03ykL+xSREQqmhGd1GZ2E7AeuHsy+7n7/e6+3t3XL1mypDrFVYk6qkVkpqtmQLQAK8vmVwTLRjCzdwOfA65294HJ7DubnXVaHdGIqR9CRGasagbEU8AaM1ttZgngBmBz+QZmdgFwH6VwOFS2aitwuZktDDqnLw+WzRmpeJS3LqnVSCYRmbFi1Tqwu+fN7DZKv9ijwAPuvtPM7gS2u/tmSqeUaoF/MjOAN9z9andvN7M/pxQyAHe6e3u1ag1LU0OW/7unLewyREQqqlpAALj7FmDLqGV3lE2/e5x9HwAeqF514WtsyPL9Z1to6x5gcW0y7HJEREaYEZ3U89XQM6p1628RmYkUECFqCp4NoY5qEZmJFBAhqs/EWbEwraGuIjIjKSBC1rgsq5FMIjIjKSBC1tRQz6ttPfQM5MMuRURkBAVEyJoasrjDiwfVihCRmUUBETKNZBKRmUoBEbJl9SkWZuIaySQiM44CImRmRlNDvQJCRGYcBcQM0NiQ5aU3uxgsFMMuRURkmAJiBmhqyJLLF9nT2h12KSIiwxQQM0DjsuDZEC06zSQiM4cCYgY4c0ktqXhEF8yJyIyigJgBohHjbUuzuuWGiMwoCogZorEhy679nbh72KWIiAAKCHCHw3sgP3D8bauoqSFLZ3+ev/6P3Wx7uZU3O/sVFiISqqo+MGhW6G2Hv3p7abr2NKhfCfUrYMFKqD89eA+WpRdUrYz/9tbFLKtP8b/+7eXhZfXpOGefVsdZS2tL78FrYU2ianWIiAyxufJX6vr163379u2T33GgG174IXTsg6NvBO/7oKMZCqNaFclsKSwWBIExPB0ESc2pEDm5Rtnh7gFefrObl9/s4qU3u3j5YOm9q//YzfxOrUty9tJSWJQCpI41p9ZSk1Tei8jkmNnT7r6+4rp5HxBjKRahty0IizeC9yA4hpb1j+pUjiYgu3xU66MsSLIrIDb5v/7dnYOd/aXgCALj5eDVP3js4rqVp6SHWxpDAXLmkhqSsejJfhsiMkeFFhBmdgXwl0AU+Dt3v2vU+kuBrwHnATe4+8Nl6wrAc8HsG+5+9XifNeUBMRH9nWWhUd76CJZ1HQTKv1+DuqWjWh8rYcHpwbIVpVaK2YQ+vlB0mo/08tLBrqDFUQqQPa3d5Iulz41GjNWLazjrtNoRLY4zTskQi6oLSmS+CyUgzCwKvAz8BtAMPAXc6O67yrZZBWSBPwQ2jwqIbnevnejnhRIQx5MfgM6Wyq2Po/tK6wq5kftEk5BZBDWLSu+ZxcH8YsicMmp+EaRPgejIU0u5fJHXDvccC47g/fX2Xob+cydiEd66pPbYqaqlpQBZviCNTTCgRGT2Gy8gqnnS+iJgt7vvDYp4ELgGGA4Id38tWDc3b0IUS8IpZ5ZelRSL0HPoWGh0tJROa/Ucht7DwSmuN0rzA+NcI5FacCwwMotJZE7hrJrFnJVZBKcuhlWlwOmPn8GenhQvHC7w8qFuXjrYxZN7D/ODZ1uGD1WbjLF6cQ2n1CRYkImzMJOgPh0/Nh28L0iX3utSMSIRBYrIXFTNgFgO7Cubbwb+yyT2T5nZdiAP3OXu/3v0Bmb2MeBjAKeffvqJVxqWSKR0yqluKay8cPxt8znoay8FR09bECCHR823wdHXoeXp0nxxcMQhUkAT0BRNHmuRLF9M7syFHCHLwXwNb/Snea0vzZtH07QcSrOzP0Vzf4p+kpV/BCMIkFKQLMyUphdk4ixIJ1hYEw+WH1u2oCZOXTKmlorIDDeTh72c4e4tZnYm8B9m9py77ynfwN3vB+6H0immMIqcNrHEsTCZCHcY6AwCpKxFMhwo7cPziSOvcVpvO6cNdHB+pWOlwGMpCskF5BILGIjX0xupoyuSpdNqafda2go1tOUzHDiSZv/BNM/2p2kZSDE4xv9i0YixIB0f0SI5FixxFtSUlmXTcepSMbKpONl06T0VV6e7yHSoZkC0ACvL5lcEyybE3VuC971m9jhwAbBn3J3kGDNI1ZdeY53iGm2oldLTBn1HStN9R6C3HetrJ9Z3hFjvETJ97Szsa4au9tI2xQrP0zYgBcV4DYXUQnKJBfTHsvREs3RbHUep5YjX0VbIcCif4eDhNC370/ysP8XBXIriONdwJmKREYFRKUSy6TjZVCx4HzmdikfUehGZgGoGxFPAGjNbTSkYbgB+eyI7mtlCoNfdB8xsMbAB+HLVKpWSybZSoNRSyXWXWiRDoTI8fYRI3xEive3E+9qp6TvCot5XguA5ysgRXoEIeMrwVD35RD35WIZctIb+SIZ+y9Bjabo9RZen6SwmOVJI0X4kQXs+waFckp39cdqLSXo8RTeZii2YeNQqhkjd8HRZsKRj1CbjZBJRapIxaoL3dDyqvheZ86oWEO6eN7PbgK2Uhrk+4O47zexOYLu7bzazC4EfAAuB95nZ5929CVgL3Bd0Xkco9UHsGuOjJExmkKwrvRaeMfH9ikXoPzocJOUBY31HsN52Ev1HSQx0k8l1lzrpB1pKYTTQBYO9lY8bH/UxkQSFeA25aA25aIb+SIZeS9NDhm5P0TmQoqM3yZFCksP5JG2DCV7JJ+n2ND2k6CJNTzA9QJxS06gkk4iSScSoSZbea5Mj54fCpCYZKwVMIkYmWXofXhaETiYZI6PQkRlGF8rJ7FTIl8Ii1126Gn6gC3JdpfeBoeWdZeuGtus8FjJD2+Um9qCmokXJRzPkomlykTT9lqHfUvSSooc0PZ6ky5N0FlJ0FhMcLSRoH0zQVUzSQ2o4aHo9STdpevnVPprRoXMsZIZCaPT0yCCqDYJnaF0ipmtdZHxhDXMVqZ5orHRvrKm4P1axWBY2Xb8aJLkeyHUTGegmkeshMbRtrqf0GuiC3KHh7UYEznH+hRUtxmCshlwkCJ1Ihj5L0UeK7sE0PbkkXZ0pOopJOvKlls4bg0k6PEW3p+kmfeyd9K/03cSjFoRIEB7JIDwSZdNlwVIpZMrXJWPqv5lPFBAikQiksqXXVCgWId9X1kLpGfk+cGw6kusmmeshORw0QejkOiDXUpoe7C4db0h87I/OR9OlwInW0B+toc8y9JWfUutL09GT4mghxZFCkvZ8kr2DCY4WUnQHp9O6SNNPgvLTaUNiERsRHkMBUlN26qy07FirpiZoEdWO2L4UOgqcmU0BITLVIhFI1JRenDY1xywWylo4Q6/OshZPaVlsoJPYQBfpgS7qh7c/AgOvHzsFN3rUWYxf+U3gFiUfr2UwVsNgtIaBsrDpDQYKdHuKzlyKjr4kHcUk7fkEbw4mODyY5GghMdyP00MKH2NUWixiI0OmLFDKw2R0C2fEqbWyvh2NUJtaCgiR2SASPTZs+WS4l24BMyJgyl5BiNhAF/HgNXKb1rJWUDcVR6JVCJxCLE0hCJtcNMNANEO/pYPWTVngDJQC52g+yZF8gv35BG25OB3F0voe0vSSpFLrBkpjJmoSx06RZcr6cjJjhMpQ8AzvU94HlIySjkfnbegoIETmEzOIp0qv2iUnd6xisTSabDgwygcIlM/3EM11Ex3oIpHrpqZ8EEFu/7F9JjgyzTGK8RrysQz5aJpcpDRwYMDS9FuS3iBEuj1FdyFJV0+Sjs4EHYU4R/NJXsvHac/F6fbScOheUvSSJD/Gr8Py0Kk0Iq00sCBKOgiidNl2mbL15dOzpT9HASEiJyYSgWRt6VU3BccbPo021EdTOXAs1010oJvoYKnvpma436YHcm0jBwtUuogToMJd94uRBIVYhnwsw2AkTS6apt/SDFiKPkvR46XTZUOh09mVoKOQoCOf4FA+wZF8jM5CMhipVgqdXpJjnl4zg0w8GOL8K2FSCp+hsEnHg+XBcOia5MhAqk/HWbEwMwX/EUZSQIjIzDBVp9HK5XMwWB4gZaPPRr0iuW4ig73Ecz2kR2x3FHK9ZceZ+Kk1CE6vRdNlQ6QzDERS9FuKPtL0kRxuzXT1JUotnkIpfI7kE+wdjHEkn6SHJH2eKr2POs12/soF/POtG6bueyv7kURE5qZYovRKL5y6Y7rDYN+xsBjsLQuf3l9ZHs11E831kMj1li76zPUE6w6XBVYQQJVEg1d5CRjFWIZCLM1gNENP5jxKN5yYWgoIEZHJMINEpvTiJPtxyg316Qz161Rq6QStGMv1EA1eiVwPNQtWHv/4J0ABISIyE5T36XBq2NUAjHPLTBERmdcUECIiUpECQkREKlJAiIhIRQoIERGpSAEhIiIVKSBERKQiBYSIiFQ0Zx45amatwOsncYjFQNsUlTPb6bsYSd/HSPo+jpkL38UZ7l7xkvA5ExAny8y2j/Vc1vlG38VI+j5G0vdxzFz/LnSKSUREKlJAiIhIRQqIY+4Pu4AZRN/FSPo+RtL3ccyc/i7UByEiIhWpBSEiIhUpIEREpKJ5HxBmdoWZvWRmu81sY9j1hMnMVprZY2a2y8x2mtknw64pbGYWNbNnzez/hF1L2MxsgZk9bGYvmtkLZvZrYdcUJjP7H8G/k+fN7Htmlgq7pqk2rwPCzKLAJuBKoBG40cwaw60qVHngD9y9EbgYuHWefx8AnwReCLuIGeIvgX9x97cB5zOPvxczWw58Aljv7udQemr0DeFWNfXmdUAAFwG73X2vu+eAB4FrQq4pNO5+wN2fCaa7KP0CWB5uVeExsxXAVcDfhV1L2MysHrgU+HsAd8+5+9FQiwpfDEibWQzIAPtDrmfKzfeAWA7sK5tvZh7/QixnZquAC4Cfh1xKmL4G/E+gGHIdM8FqoBX4RnDK7e/MrCbsosLi7i3AV4A3gANAh7v/a7hVTb35HhBSgZnVAo8An3L3zrDrCYOZ/SZwyN2fDruWGSIGvB34G3e/AOgB5m2fnZktpHS2YTXQANSY2U3hVjX15ntAtAAry+ZXBMvmLTOLUwqH77j798OuJ0QbgKvN7DVKpx7/u5l9O9ySQtUMNLv7UIvyYUqBMV+9G3jV3VvdfRD4PvBfQ65pys33gHgKWGNmq80sQamTaXPINYXGzIzSOeYX3P2rYdcTJnf/rLuvcPdVlP6/+A93n3N/IU6Uux8E9pnZ2cGidwG7QiwpbG8AF5tZJvh38y7mYKd9LOwCwuTueTO7DdhKaRTCA+6+M+SywrQB+B3gOTPbESz7I3ffEl5JMoP8PvCd4I+pvcBHQ64nNO7+czN7GHiG0ui/Z5mDt93QrTZERKSi+X6KSURExqCAEBGRihQQIiJSkQJCREQqUkCIiEhFCgiRGcDM3qk7xspMo4AQEZGKFBAik2BmN5nZL8xsh5ndFzwvotvM/iJ4NsC/m9mSYNt1Zvakmf2nmf0guH8PZvZWM/uxmf3SzJ4xs7cEh68te97Cd4IrdEVCo4AQmSAzWwtcD2xw93VAAfgQUANsd/cm4AngT4NdvgV8xt3PA54rW/4dYJO7n0/p/j0HguUXAJ+i9GySMyld2S4Smnl9qw2RSXoX8A7gqeCP+zRwiNLtwP8x2ObbwPeD5ycscPcnguXfBP7JzOqA5e7+AwB37wcIjvcLd28O5ncAq4CfVv2nEhmDAkJk4gz4prt/dsRCsz8Ztd2J3r9moGy6gP59Ssh0iklk4v4d+C0zOxXAzE4xszMo/Tv6rWCb3wZ+6u4dwBEzuyRY/jvAE8GT+prN7NrgGEkzy0znDyEyUfoLRWSC3H2Xmf0x8K9mFgEGgVspPTznomDdIUr9FAA3A/cGAVB+99PfAe4zszuDY3xgGn8MkQnT3VxFTpKZdbt7bdh1iEw1nWISEZGK1IIQEZGK1IIQEZGKFBAiIlKRAkJERCpSQIiISEUKCBERqej/A5QdHllXRfVkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습결과 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], label = 'train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], label = 'val loss')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "616d312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행하는 함수만들기\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):  \n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence]) # init_sentence 텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64) # 텐서로 변환\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장 만들기(루프를 돌면서 init_sentence에 단어를 하나씩 생성)\n",
    "    while True:\n",
    "        predict = model(test_tensor) # 입력받은 문장의 텐서 입력\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] # 예측된 값 중 가장 높은 확률인 word index 뽑아내기\n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1) # 예측된 word index를 문장 뒤에 붙이기\n",
    "        if predict_word.numpy()[0] == end_token: break # 모델이 <end>를 예측했거나\n",
    "        if test_tensor.shape[1] >= max_len: break # max_len에 도달했다면 문장 생성을 마침\n",
    "            \n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환\n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated #최종적으로 모델이 생성한 문장을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8643602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , i m a girl <end> '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)\n",
    "# generate_text 함수에 model이라 정의한 모델을 이용해서 i love 로 시작되는 문장을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416f071",
   "metadata": {},
   "source": [
    "## 회고\n",
    "1. 데이터의 전처리 및 구성과정이 체계적으로 진행되었는가? 특수문자 제거, 토크나이저 생성, 패딩 처리의 작업들이 빠짐없이 진행되었는가?  \n",
    "특수문자 제거, 토크나이저 생성, 패딩 처리의 작업을 진행하여 데이터의 전처리 및 구성을 진행하였다. 그런데 그 과정에서 < > 사이에 쓰여진 문자들이 깃허브에 올리는 과정에서 날아간다는 사실을 알게 되었다. 이유를 잘 모르겠다.(창호 퍼실님의 도움으로 깃헙에 코드를 올리면 마크다운화되어 코드가 올라간다는 사실을 알게 되었다. 해결 방법은 아직 모르겠다.)  \n",
    "2. 가사 텍스트 생성 모델이 정상적으로 동작하는가? 텍스트 제너레이션 결과로 생성된 문장이 해석 가능한 문장인가?  \n",
    "중간에 실수가 있어서 학습을 총 3번 돌렸는데, 세번째 학습을 돌리고 i love you , i m a girl라는 결과를 얻었다. 문법적으로 잘못된 것도 없고, 해석도 가능한 문장으로 잘 나왔다. 다만 이 문장이 나오기 전에 두번째 학습을 돌린 후 i love t t meenie meenie meenie meenie meenie meenie meenie meenie meenie meenie meenie가 나왔는데 무엇인가 잘못되었다는 것을 깨닫고 코드를 다시 한 번 돌아봤다. < > 사이에 쓰여진 문자들을 제대로 쓰지 않았고, 그걸로 인해 이상한 결과가 나왔다. 그래서 다시 학습을 시켜 결과물을 잘 받았다.  \n",
    "3. 텍스트 생성모델이 안정적으로 학습되었는가? 텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?  \n",
    "첫번째 epoch일 때 validation loss는 0.1593으로 생각보다 낮았다. 열번째 epoch에서 validation loss는 0.1247로 첫번째 epoch일 때보다 loss가 더 줄어들기는 했다.  \n",
    "4. 프로젝트를 진행하면서 느낀 점 : 학습을 진행하는 과정에서 위에 코드를 잘못 입력했는데 그걸로 인해 결과가 완전히 이상해졌다. 학습을 시키면서 시간이 굉장히 많이 걸렸는데 그 과정을 3번이나 반복해서 진행하면서 코드 입력을 더더욱 조심해야겠다고 생각했다. 그리고 batch size와 embedding size, hidden size가 다 크다고 항상 좋은 것은 아니라는 것을 깨닫게 되었다. 데이터의 크기에 따라 알맞은 size를 찾는 것도 중요하다는 것을 느끼게되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f244c",
   "metadata": {},
   "source": [
    "## Reference\n",
    "[문장분할](https://rfriend.tistory.com/748)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
