{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632fade1",
   "metadata": {},
   "source": [
    "# 단어 Level로 번역기 업그레이드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16af2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 import\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354a53f",
   "metadata": {},
   "source": [
    "## Step 1 & 2. 정제, 정규화, 전처리 및 디코더의 문장에 시작 토큰과 종료 토큰을 넣어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebcdb0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35098</th>\n",
       "      <td>He bragged about it.</td>\n",
       "      <td>Il s'en est vanté.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140475</th>\n",
       "      <td>How long did you stay at the party?</td>\n",
       "      <td>Combien de temps êtes-vous restés à la fête ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18508</th>\n",
       "      <td>I could kiss you.</td>\n",
       "      <td>Je pourrais t'embrasser.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77934</th>\n",
       "      <td>He began to learn English.</td>\n",
       "      <td>Il a commencé à apprendre l'anglais.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32385</th>\n",
       "      <td>This is really low.</td>\n",
       "      <td>C'est très bas.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        eng  \\\n",
       "35098                  He bragged about it.   \n",
       "140475  How long did you stay at the party?   \n",
       "18508                     I could kiss you.   \n",
       "77934            He began to learn English.   \n",
       "32385                   This is really low.   \n",
       "\n",
       "                                                  fra  \\\n",
       "35098                              Il s'en est vanté.   \n",
       "140475  Combien de temps êtes-vous restés à la fête ?   \n",
       "18508                        Je pourrais t'embrasser.   \n",
       "77934            Il a commencé à apprendre l'anglais.   \n",
       "32385                                 C'est très bas.   \n",
       "\n",
       "                                                       cc  \n",
       "35098   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "140475  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "18508   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "77934   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "32385   CC-BY 2.0 (France) Attribution: tatoeba.org #4...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 불러오기\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f8cf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14037</th>\n",
       "      <td>I fed the horse.</td>\n",
       "      <td>J'ai nourri le cheval.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682</th>\n",
       "      <td>Stop squabbling.</td>\n",
       "      <td>Arrêtez de vous chamailler.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19207</th>\n",
       "      <td>I was very happy.</td>\n",
       "      <td>J'étais très heureuse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14674</th>\n",
       "      <td>I'll follow you.</td>\n",
       "      <td>Je te suivrai.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>You're funny.</td>\n",
       "      <td>Vous êtes marrants.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     eng                          fra\n",
       "14037   I fed the horse.       J'ai nourri le cheval.\n",
       "15682   Stop squabbling.  Arrêtez de vous chamailler.\n",
       "19207  I was very happy.       J'étais très heureuse.\n",
       "14674   I'll follow you.               Je te suivrai.\n",
       "6537       You're funny.          Vous êtes marrants."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼 cc제거 및 3만3천개 샘플 사용\n",
    "lines = lines[['eng', 'fra']][:33000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc8a663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>Who painted that?</td>\n",
       "      <td>/t Qui a peint cela ? /n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18153</th>\n",
       "      <td>He made no reply.</td>\n",
       "      <td>/t Il ne fit pas de réponse. /n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11279</th>\n",
       "      <td>It's expensive.</td>\n",
       "      <td>/t C'est cher. /n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21793</th>\n",
       "      <td>What did you say?</td>\n",
       "      <td>/t Qu'avez-vous dit ? /n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14499</th>\n",
       "      <td>I totally agree.</td>\n",
       "      <td>/t Je suis entièrement d'accord. /n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     eng                                  fra\n",
       "21998  Who painted that?             /t Qui a peint cela ? /n\n",
       "18153  He made no reply.      /t Il ne fit pas de réponse. /n\n",
       "11279    It's expensive.                    /t C'est cher. /n\n",
       "21793  What did you say?             /t Qu'avez-vous dit ? /n\n",
       "14499   I totally agree.  /t Je suis entièrement d'accord. /n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '/t'\n",
    "eos_token = '/n'\n",
    "lines.fra = lines.fra.apply(lambda x : '/t ' + x + ' /n')\n",
    "# fra 각 열에 앞 뒤로 각각 \\t와 \\n을 넣기 \n",
    "\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21da4f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29967</th>\n",
       "      <td>[i, like, mathematics, .]</td>\n",
       "      <td>[, t, j, aime, les, math, matiques, ., n, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12162</th>\n",
       "      <td>[tom, is, packing, .]</td>\n",
       "      <td>[, t, tom, fait, ses, bagages, ., n, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8922</th>\n",
       "      <td>[tom, might, win, .]</td>\n",
       "      <td>[, t, il, se, pourrait, que, tom, gagne, ., n, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>[we, are, here, .]</td>\n",
       "      <td>[, t, nous, y, sommes, ., n, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29370</th>\n",
       "      <td>[how, about, tomorrow, ?]</td>\n",
       "      <td>[, t, que, dis, tu, de, demain, ?, n, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             eng  \\\n",
       "29967  [i, like, mathematics, .]   \n",
       "12162      [tom, is, packing, .]   \n",
       "8922        [tom, might, win, .]   \n",
       "4121          [we, are, here, .]   \n",
       "29370  [how, about, tomorrow, ?]   \n",
       "\n",
       "                                                    fra  \n",
       "29967       [, t, j, aime, les, math, matiques, ., n, ]  \n",
       "12162            [, t, tom, fait, ses, bagages, ., n, ]  \n",
       "8922   [, t, il, se, pourrait, que, tom, gagne, ., n, ]  \n",
       "4121                     [, t, nous, y, sommes, ., n, ]  \n",
       "29370           [, t, que, dis, tu, de, demain, ?, n, ]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sentence_encoder(sentence):\n",
    "    # 소문자로 바꾸기\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    # 구두점(Punctuation)을 단어와 분리\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 특수문자(구두점) 양쪽에 공백 넣기\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개의 공백은 하나의 공백으로 바꾸기\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!]+\", \" \", sentence) # a-zA-Z?.!가 아닌 모든 문자를 하나의 공백으로 바꾸기\n",
    "    sentence = sentence.strip() # 다시 양쪽 공백 지우기\n",
    "    sentence = sentence.split(\" \") # 공백을 기준으로 분리하기\n",
    "    return sentence\n",
    "\n",
    "def preprocess_sentence_decoder(sentence):\n",
    "    # 소문자로 바꾸기\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    # 구두점(Punctuation)을 단어와 분리\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = ' ' + sentence + ' '\n",
    "    sentence = sentence.split(\" \")\n",
    "    return sentence\n",
    "\n",
    "lines.eng = lines.eng.apply(lambda x : preprocess_sentence_encoder(x))\n",
    "lines.fra = lines.fra.apply(lambda x : preprocess_sentence_decoder(x))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71c22c",
   "metadata": {},
   "source": [
    "- 구두점을 단어와 분리하기 위해서 처음에 특수문자를 문자열화해서 자르려고 시도했지만 당연히 안됐다. 여러 방법을 찾아보다가 주완님과 상규님의 도움을 받아서 해결했다. 그래서 인공작사가 만들기 문장 전처리를 참고해서 특수문자 양쪽에 공백을 넣고 그 공백을 기준으로 split하면 된다는 생각이 들었고, 그렇게 해결했다.\n",
    "- lambda 사용 방법을 정확하게 모르고 있어서 다시 한 번 찾아봤는데, \"lambda 뒤에 나오는 인수는 함수에서 사용될 변수들을 정의하며 인수에서 정의 된 변수를 함수에 적용시킨 결과를 도출한다.\"라는 말을 보고 lambda 뒤에 함수를 넣기에는 너무 길기 때문에 따로 함수를 정의한 후 넣어주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b4402",
   "metadata": {},
   "source": [
    "## Step 3. 케라스의 토크나이저로 텍스트를 숫자로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057b1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화하기\n",
    "# 영어\n",
    "eng_tokenizer = Tokenizer(char_level=True)   # 문자 단위로 Tokenizer를 생성\n",
    "eng_tokenizer.fit_on_texts(lines.eng)               # 33000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "\n",
    "# 프랑스어\n",
    "fra_tokenizer = Tokenizer(char_level=True)   # 문자 단위로 Tokenizer를 생성\n",
    "fra_tokenizer.fit_on_texts(lines.fra)                 # 50000개의 행을 가진 fra의 각 행에 토큰화를 수행\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)     # 단어를 숫자값 인덱스로 변환하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4097350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 4671\n",
      "프랑스어 단어장의 크기 : 7453\n",
      "영어 시퀀스의 최대 길이 8\n",
      "프랑스어 시퀀스의 최대 길이 19\n"
     ]
    }
   ],
   "source": [
    "# 단어장 만들기\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "\n",
    "# 영어 데이터와 프랑스어 데이터의 최대 길이(for 패딩)\n",
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "\n",
    "# 전체적인 통계 정보\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c2a6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 74, 9, 3], [2, 364, 4, 3], [2, 28, 511, 9, 3]]\n",
      "[[2, 74, 9, 3], [2, 364, 4, 3], [2, 28, 511, 9, 3]]\n"
     ]
    }
   ],
   "source": [
    "sos_token = ''\n",
    "eos_token = ''\n",
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]\n",
    "\n",
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c715ec7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 8)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 19)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 19)\n"
     ]
    }
   ],
   "source": [
    "# 패딩하기\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef67c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터를 분리하기 전 데이터를 섞어주기\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628f932",
   "metadata": {},
   "source": [
    "- 원-핫 인코딩을 넣었을 때 계속해서 커널이 죽는 경우가 발생했다. 다른 사람의 코드를 참고했을 때, 원-핫 인코딩이 들어가있지 않았기 때문에 원-핫 인코딩을 빼고 데이터를 섞어주었다. 경덕님의 도움도 받았는데 embedding을 하기 때문에 따로 원-핫 인코딩을 할 필요가 없다고 하셨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165116cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (33000, 8)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (33000, 19)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (33000, 19)\n"
     ]
    }
   ],
   "source": [
    "# 33000건 중 3000건 검증데이터로, 나머지를 학습데이터로 분리\n",
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6327daa",
   "metadata": {},
   "source": [
    "## Step 4. 임베딩 층(Embedding layer) 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c71111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Masking\n",
    "\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "# encoder embedding\n",
    "enc_emb = Embedding(eng_vocab_size, 256, input_length=max_eng_seq_len)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(units = 256, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "132ab839",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "# decoder embedding\n",
    "dec_emb = Embedding(fra_vocab_size, 256)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(dec_masking, initial_state = encoder_states)\n",
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92de5cc",
   "metadata": {},
   "source": [
    "## Step 5. 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de034422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    1195776     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    1907968     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 256)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 256)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 525312      masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 7453)   1915421     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,069,789\n",
      "Trainable params: 6,069,789\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b405e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 26s 20ms/step - loss: 1.1848 - accuracy: 0.8315 - val_loss: 0.5651 - val_accuracy: 0.9264\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.4002 - accuracy: 0.9480 - val_loss: 0.3244 - val_accuracy: 0.9608\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2285 - accuracy: 0.9710 - val_loss: 0.2181 - val_accuracy: 0.9756\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.1359 - accuracy: 0.9825 - val_loss: 0.1604 - val_accuracy: 0.9832\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0800 - accuracy: 0.9891 - val_loss: 0.1273 - val_accuracy: 0.9875\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0448 - accuracy: 0.9935 - val_loss: 0.1061 - val_accuracy: 0.9903\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0237 - accuracy: 0.9957 - val_loss: 0.0949 - val_accuracy: 0.9919\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.0879 - val_accuracy: 0.9925\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.0829 - val_accuracy: 0.9930\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0792 - val_accuracy: 0.9931\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 6.9177e-04 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9933\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 3.1896e-04 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9935\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8215e-04 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9936\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.1727e-04 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9937\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 7.9106e-05 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9938\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 5.4511e-05 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9938\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 3.8536e-05 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9939\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 2.8052e-05 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9939\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 2.0877e-05 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9939\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5938e-05 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9940\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.2425e-05 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9940\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 9.9034e-06 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9941\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 8.0385e-06 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9941\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 6.6523e-06 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9942\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 5.6081e-06 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9941\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 4.8218e-06 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9941\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 4.2146e-06 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9942\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 3.7505e-06 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9941\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 3.3674e-06 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9941\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 3.0558e-06 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9941\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 2.7974e-06 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9941\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 2.5774e-06 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9942\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 2.3916e-06 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9941\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 2.2320e-06 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9942\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 2.0922e-06 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9942\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.9710e-06 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9942\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8621e-06 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9942\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7652e-06 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9942\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6777e-06 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9942\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5991e-06 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9942\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5271e-06 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9942\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4619e-06 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9942\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4019e-06 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9942\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.3470e-06 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9942\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.2963e-06 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9942\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.2492e-06 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9942\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.2057e-06 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9942\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.1652e-06 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9942\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.1271e-06 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9942\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.0918e-06 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9942\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "         validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "         batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d271bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss') # bo는 파란색 점\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss') # b는 파란색 실선\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653da09",
   "metadata": {},
   "source": [
    "## Step 6. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8beadca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 256)         1195776   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 525312    \n",
      "=================================================================\n",
      "Total params: 1,721,088\n",
      "Trainable params: 1,721,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 인코더 정의\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "201ec9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "dec_emb2 = Embedding(fra_vocab_size, 256)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539a8c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    1907968     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_2[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 7453)   1915421     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,348,701\n",
      "Trainable params: 4,348,701\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더 출력층 재설계\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9933bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어에서 정수로, 정수에서 단어로 바꾸는 사전 만들기(테스트 결과 해석을 위해서)\n",
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6447b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode_sequence() 함수만들기\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # 에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra2idx['']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # 에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8faa744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + idx2eng[i]+' '\n",
    "    return temp\n",
    "\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=fra2idx['']) and i!=fra2idx['']):\n",
    "            temp = temp + idx2fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5277e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: this is silly . \n",
      "정답 문장: t c est idiot ! n \n",
      "번역기가 번역한 문장:  t t t chichement chichemen\n",
      "-----------------------------------\n",
      "입력 문장: can you forgive me ? \n",
      "정답 문장: t peux tu me pardonner ? n \n",
      "번역기가 번역한 문장:  t t t chichement chichemen\n",
      "-----------------------------------\n",
      "입력 문장: you have to go . \n",
      "정답 문장: t il vous faut partir . n \n",
      "번역기가 번역한 문장:  t t t chichement chichemen\n",
      "-----------------------------------\n",
      "입력 문장: i ve upset you . \n",
      "정답 문장: t je t ai contrari e . n \n",
      "번역기가 번역한 문장:  t t t chichement chichemen\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_truncate_execution_to_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_truncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'assign'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_819/3905126911.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m333\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1004\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'입력 문장:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2src\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_819/28961154.py\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 입력으로부터 인코더의 상태를 얻음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstates_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 에 해당하는 원-핫 벡터 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1745\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_truncate_execution_to_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_truncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "# 출력 결과 테스트\n",
    "for seq_index in [1,100,333,1004,3000]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
    "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77b479",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62147262",
   "metadata": {},
   "source": [
    "## 회고\n",
    "1. 구두점, 대소문자, 띄어쓰기 등 번역기 모델에 요구되는 전처리가 잘 이루어졌는가?  \n",
    "구두점, 대소문자, 띄어쓰기에 대한 전처리는 잘 이루어진 거 같다. 다만 참조 코드를 보면 프랑스어의 경우 악센트가 있는 것을 모두 제거해주었는데 그 부분을 추가하면 동일한 단어가 늘어나면서 학습이 더 잘 될 것이라고 예측된다. 이번에 해보지 못했지만 마지막 결과에 error를 해결하면서 전처리를 더 잘 해보고 싶은 마음이 생겼다.  \n",
    "2. seq2seq 기반의 번역기 모델이 정상적으로 구동되는가?  \n",
    "seq2seq 모델 훈련결과를 그래프로 출력했을 때, validation loss 그래프가 우하향하는 경향성을 보이며 학습이 진행되기는 했지만 accuracy가 1이 나와서 제대로 학습이 된 건지는 의문이 든다.  \n",
    "3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었는가?  \n",
    "테스트용 디코더 모델을 정상적으로 만들었던 거 같은데 테스트 결과도 이상했고, error도 발생했다. 도저히 해결할 힘이 남아있지 않아 다음에 도전해보기로 했다.  \n",
    "4. 프로젝트를 진행하면서 느낀 점 : 이것저것 시도해보고 싶었는데 단순히 이해하는 것만으로도 너무 힘들고 벅찼다. 다른 사람들의 코드를 참고했음에도 너무 너무 어려웠다. 머리를 환기시킨 후에 다시 도전해봐야겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610a140",
   "metadata": {},
   "source": [
    "## Reference\n",
    "[lambda](https://sophihappy.tistory.com/2)  \n",
    "[전체적인 코드 참조1](https://wikidocs.net/86900)  \n",
    "[전체적인 코드 참조2](https://github.com/PEBpung/Aiffel/blob/master/Project/Exploration/E15.%20%EB%8B%A8%EC%96%B4%20Level%EB%A1%9C%20seq2seq%20%EB%B2%88%EC%97%AD%EA%B8%B0%20%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
